{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\stuti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import regex as re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from langdetect import detect, DetectorFactory, LangDetectException\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>URL</th>\n",
       "      <th>transcript</th>\n",
       "      <th>Comedian Name</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Unique ID</th>\n",
       "      <th>neg_polarity</th>\n",
       "      <th>neu_polarity</th>\n",
       "      <th>pos_polarity</th>\n",
       "      <th>compound</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://scrapsfromtheloft.com/comedy/pete-holm...</td>\n",
       "      <td>\\r\\n \\r\\n [audience cheering and applauding] \\...</td>\n",
       "      <td>Pete Holmes</td>\n",
       "      <td>10068</td>\n",
       "      <td>0</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.256</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.504545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                URL  \\\n",
       "0           0  https://scrapsfromtheloft.com/comedy/pete-holm...   \n",
       "\n",
       "                                          transcript Comedian Name  \\\n",
       "0  \\r\\n \\r\\n [audience cheering and applauding] \\...   Pete Holmes   \n",
       "\n",
       "   word_count  Unique ID  neg_polarity  neu_polarity  pos_polarity  compound  \\\n",
       "0       10068          0         0.056         0.688         0.256       1.0   \n",
       "\n",
       "   subjectivity  \n",
       "0      0.504545  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('polarity_subjectivity_data_without_LemmStemm.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuations from transcript\n",
    "df['transcript'] = df['transcript'].str.replace(f'[{string.punctuation}]', '', regex = True)\n",
    "\n",
    "# Removing special characters\n",
    "df['transcript'] = df['transcript'].apply(lambda x: re.sub('[^\\w\\s]', '', x))\n",
    "\n",
    "# Decapitalizing text\n",
    "df['transcript'] = df['transcript'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>URL</th>\n",
       "      <th>transcript</th>\n",
       "      <th>Comedian Name</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Unique ID</th>\n",
       "      <th>neg_polarity</th>\n",
       "      <th>neu_polarity</th>\n",
       "      <th>pos_polarity</th>\n",
       "      <th>compound</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://scrapsfromtheloft.com/comedy/pete-holm...</td>\n",
       "      <td>\\r\\n \\r\\n audience cheering and applauding \\r\\...</td>\n",
       "      <td>Pete Holmes</td>\n",
       "      <td>10068</td>\n",
       "      <td>0</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.256</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.504545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                URL  \\\n",
       "0           0  https://scrapsfromtheloft.com/comedy/pete-holm...   \n",
       "\n",
       "                                          transcript Comedian Name  \\\n",
       "0  \\r\\n \\r\\n audience cheering and applauding \\r\\...   Pete Holmes   \n",
       "\n",
       "   word_count  Unique ID  neg_polarity  neu_polarity  pos_polarity  compound  \\\n",
       "0       10068          0         0.056         0.688         0.256       1.0   \n",
       "\n",
       "   subjectivity  \n",
       "0      0.504545  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminating stop words\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "df['tokens_lst'] = df['transcript'].apply(lambda x: [w for w in word_tokenize(x) if not w.lower() in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting most frequently ocurring words in the corpus\n",
    "txt = df['tokens_lst'].apply(lambda x: ' '.join(x))\n",
    "tokens = [w for lst in txt.apply(word_tokenize) for w in lst]\n",
    "word_cnt = FreqDist(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each word in list to adjective, nouns, verbs, adverbs\n",
    "allowed_tag = ['NN', 'NNS', 'NNP', 'NNPS',     \n",
    "               'RB', 'RBR', 'RBS', \n",
    "               'JJ', 'JJR', 'JJS',\n",
    "               'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "\n",
    "token_tag_lst = df['tokens_lst'].apply(lambda x: pos_tag(x))\n",
    "df['all_tokens'] = token_tag_lst\n",
    "\n",
    "df['select_tokens'] = df['all_tokens'].apply(lambda x: [word for word, tag in x if tag in allowed_tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>URL</th>\n",
       "      <th>transcript</th>\n",
       "      <th>Comedian Name</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Unique ID</th>\n",
       "      <th>neg_polarity</th>\n",
       "      <th>neu_polarity</th>\n",
       "      <th>pos_polarity</th>\n",
       "      <th>compound</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>tokens_lst</th>\n",
       "      <th>all_tokens</th>\n",
       "      <th>select_tokens</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://scrapsfromtheloft.com/comedy/pete-holm...</td>\n",
       "      <td>\\r\\n \\r\\n audience cheering and applauding \\r\\...</td>\n",
       "      <td>Pete Holmes</td>\n",
       "      <td>10068</td>\n",
       "      <td>0</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.256</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.504545</td>\n",
       "      <td>[audience, cheering, applauding, hello, hello,...</td>\n",
       "      <td>[(audience, NN), (cheering, VBG), (applauding,...</td>\n",
       "      <td>[audience, cheering, applauding, hello, hello,...</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://scrapsfromtheloft.com/comedy/jeff-dunh...</td>\n",
       "      <td>\\r\\n \\r\\n im funnier than he is but they told ...</td>\n",
       "      <td>Jeff Dunham</td>\n",
       "      <td>4943</td>\n",
       "      <td>1</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.264</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.535705</td>\n",
       "      <td>[im, funnier, told, introduce, heres, jeff, du...</td>\n",
       "      <td>[(im, NN), (funnier, NN), (told, VBD), (introd...</td>\n",
       "      <td>[im, funnier, told, introduce, heres, jeff, du...</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://scrapsfromtheloft.com/comedy/taylor-to...</td>\n",
       "      <td>\\r\\n \\r\\n in her 2024 netflix standup comedy s...</td>\n",
       "      <td>Taylor Tomlinson</td>\n",
       "      <td>11197</td>\n",
       "      <td>2</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.206</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.510567</td>\n",
       "      <td>[2024, netflix, standup, comedy, special, tayl...</td>\n",
       "      <td>[(2024, CD), (netflix, JJ), (standup, NN), (co...</td>\n",
       "      <td>[netflix, standup, comedy, special, taylor, to...</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                URL  \\\n",
       "0           0  https://scrapsfromtheloft.com/comedy/pete-holm...   \n",
       "1           1  https://scrapsfromtheloft.com/comedy/jeff-dunh...   \n",
       "2           2  https://scrapsfromtheloft.com/comedy/taylor-to...   \n",
       "\n",
       "                                          transcript     Comedian Name  \\\n",
       "0  \\r\\n \\r\\n audience cheering and applauding \\r\\...       Pete Holmes   \n",
       "1  \\r\\n \\r\\n im funnier than he is but they told ...       Jeff Dunham   \n",
       "2  \\r\\n \\r\\n in her 2024 netflix standup comedy s...  Taylor Tomlinson   \n",
       "\n",
       "   word_count  Unique ID  neg_polarity  neu_polarity  pos_polarity  compound  \\\n",
       "0       10068          0         0.056         0.688         0.256       1.0   \n",
       "1        4943          1         0.062         0.673         0.264       1.0   \n",
       "2       11197          2         0.077         0.717         0.206       1.0   \n",
       "\n",
       "   subjectivity                                         tokens_lst  \\\n",
       "0      0.504545  [audience, cheering, applauding, hello, hello,...   \n",
       "1      0.535705  [im, funnier, told, introduce, heres, jeff, du...   \n",
       "2      0.510567  [2024, netflix, standup, comedy, special, tayl...   \n",
       "\n",
       "                                          all_tokens  \\\n",
       "0  [(audience, NN), (cheering, VBG), (applauding,...   \n",
       "1  [(im, NN), (funnier, NN), (told, VBD), (introd...   \n",
       "2  [(2024, CD), (netflix, JJ), (standup, NN), (co...   \n",
       "\n",
       "                                       select_tokens  diff  \n",
       "0  [audience, cheering, applauding, hello, hello,...   553  \n",
       "1  [im, funnier, told, introduce, heres, jeff, du...   168  \n",
       "2  [netflix, standup, comedy, special, taylor, to...   565  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diff'] = df.apply(lambda r: len(r['tokens_lst']) - len(r['select_tokens']), axis=1)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('preprocess_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing the final tokens column\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "def lem_tokens(tokens):\n",
    "    return [lem.lemmatize(token) for token in tokens]\n",
    "\n",
    "df['lem_tokens'] = df['select_tokens'].apply(lambda x: lem_tokens(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "DetectorFactory.seed = 0\n",
    "\n",
    "def lang_detect(transcripts):\n",
    "    try:\n",
    "        return detect(transcripts)\n",
    "    except LangDetectException:\n",
    "        return None\n",
    "\n",
    "df['language'] = df['transcript'].apply(lang_detect)\n",
    "\n",
    "df = df[df['language'] == 'en']\n",
    "\n",
    "df['lem_txt'] = df['lem_tokens'].apply(lambda x: ' '.join(x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Dirichlet Allocation - Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each word in list to adjective, nouns, verbs, adverbs\n",
    "noun_tag = ['NN', 'NNP']\n",
    "\n",
    "#token_tag_lst = df['tokens_lst'].apply(lambda x: pos_tag(x))\n",
    "#df['all_tokens'] = token_tag_lst\n",
    "\n",
    "df['select_tokens'] = df['all_tokens'].apply(lambda x: [word for word, tag in x if tag in noun_tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1780"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['select_tokens'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "\n",
    "tf_idf = TfidfVectorizer()\n",
    "tf_mat = tf_idf.fit_transform(df['lem_txt'])\n",
    "\n",
    "num_topics = 5\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components = num_topics, random_state = 0)\n",
    "lda.fit(tf_mat)\n",
    "\n",
    "def topics(model, vect, top_n = 10):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print('Topic {}:'.format(idx))\n",
    "        top_words_with_scores = [(word, score) for word, score in zip(vect.get_feature_names_out()[topic.argsort()[:-top_n - 1:-1]], topic[topic.argsort()[:-top_n - 1:-1]])]\n",
    "        print(top_words_with_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('ryanhamiltonlivecom', 0.20004714002034601), ('ohhs', 0.20004714002034601), ('baffle', 0.20004714002034601), ('tadaaa', 0.200046617220609), ('handheld', 0.200046617220609), ('mmmhmm', 0.200046617220609), ('amd', 0.200046617220609), ('awwwww', 0.20004096942679275), ('downfield', 0.2000404158521646), ('pastoral', 0.2000404158521646)]\n",
      "Topic 1:\n",
      "[('ryanhamiltonlivecom', 0.20004713999600698), ('ohhs', 0.20004713999600698), ('baffle', 0.20004713999600698), ('tadaaa', 0.20004661684525069), ('handheld', 0.20004661684525069), ('mmmhmm', 0.20004661684525069), ('amd', 0.20004661684525069), ('awwwww', 0.200040969096327), ('downfield', 0.200040415801951), ('pastoral', 0.200040415801951)]\n",
      "Topic 2:\n",
      "[('im', 75.17536740931945), ('youre', 61.15024014450721), ('dont', 60.36569648753485), ('audience', 49.11723363265406), ('time', 40.22740031112249), ('man', 39.916950464927446), ('laughter', 39.47992291138559), ('gon', 39.15323933621652), ('cause', 32.0602567743328), ('thing', 30.15025554570044)]\n",
      "Topic 3:\n",
      "[('ryanhamiltonlivecom', 0.20004714002251062), ('ohhs', 0.20004714002251062), ('baffle', 0.20004714002251062), ('tadaaa', 0.2000466169811192), ('handheld', 0.2000466169811192), ('mmmhmm', 0.2000466169811192), ('amd', 0.2000466169811192), ('awwwww', 0.20004096921575165), ('downfield', 0.2000404158347069), ('pastoral', 0.2000404158347069)]\n",
      "Topic 4:\n",
      "[('bolsonaro', 0.6666324402387405), ('deforestation', 0.5643698512413846), ('guajajara', 0.4343827395693196), ('jair', 0.43438273956845136), ('jbs', 0.40778874147349475), ('s√¥nia', 0.38085379010937237), ('rainforest', 0.3457268031968537), ('batista', 0.3256968901058608), ('joesley', 0.2705140027244833), ('temer', 0.2465200102154125)]\n"
     ]
    }
   ],
   "source": [
    "topics(lda, tf_idf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
